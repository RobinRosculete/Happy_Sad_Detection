{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854ebf1a-de54-49f9-8a03-6e57ff11e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face detection using haarcascade from opencv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import pywt\n",
    "from math import gamma\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bf8567b-6f4b-4920-b21e-82f790071f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./opncv/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('./opncv/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1b1f8d-e6f1-40b5-929e-9eb4127c071f",
   "metadata": {},
   "source": [
    "## Requierd Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62d6293b-1cb3-43f6-9cf9-efc79be85321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function purpose to crop an image that contains both face and two eyes\n",
    "def get_cropped_image_if_eyes(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    faces = face_cascade.detectMultiScale(image,1.3, 5)\n",
    "    for (face_x,face_y,face_w,face_h) in faces:\n",
    "     roi_color = image[face_y:face_y+face_h, face_x:face_x+face_w]\n",
    "     eyes = eye_cascade.detectMultiScale(roi_color)\n",
    "     if len(eyes) > 2:\n",
    "         return roi_color\n",
    "     else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aec7606-ca0b-414e-8269-5f59a4df322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet2d(image, mode='haar', level=1):\n",
    "    imageArray = image\n",
    "    #converting to gray scale\n",
    "    imageArray = cv2.cvtColor(imageArray, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    #convertion values to float\n",
    "    imageArray = np.float32(imageArray)\n",
    "    imageArray /= 255\n",
    "    \n",
    "    #calculating coefficents\n",
    "    coefficients = pywt.wavedec2(imageArray, mode,level=level)\n",
    "    \n",
    "    #process coefficients\n",
    "    coefficients_H=list(coefficients)\n",
    "    coefficients_H[0] *= 0\n",
    "    \n",
    "    #recunstructing image\n",
    "    imageArray_H = pywt.waverec2(coefficients_H,mode)\n",
    "    imageArray_H *= 255\n",
    "    imageArray_H= np.uint8(imageArray_H)\n",
    "    return imageArray_H\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f2953d4-f8c0-4393-b346-a50e2103835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path To Face's data\n",
    "path_to_data = \"./data\"\n",
    "path_to_cropped_data = \"./data/cropped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eeac375-4ef2-4ef0-87a1-0d1d271dba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directories =[]\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "         image_directories.append(entry.path)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37236073-d777-47d8-be79-61cecfba90c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(path_to_cropped_data):\n",
    "  shutil.rmtree(path_to_cropped_data) #delete path\n",
    "os.mkdir(path_to_cropped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc5af5ba-ca1d-425b-a66b-a8f6eefab3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image_directories = []\n",
    "person_file_names_dictionery = {} #dictonery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38ed55f5-26f3-42e4-8527-55b8cd8ce932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gettig name of image directory (Happy Person or Sad Person face directory)\n",
    "for image_directorie in image_directories:\n",
    "     count = 1\n",
    "     person_face = image_directorie.split('/')[-1] #geeting diclrectory name\n",
    "   \n",
    "     person_file_names_dictionery[person_face] = []\n",
    "     \n",
    "     for entry in os.scandir(image_directorie):\n",
    "       \n",
    "         roi_color = get_cropped_image_if_eyes(entry.path)\n",
    "         if roi_color is not None:\n",
    "              cropped_folder = path_to_cropped_data+ \"/\" + person_face\n",
    "              if not os.path.exists(cropped_folder):\n",
    "                  os.makedirs(cropped_folder)\n",
    "                  cropped_image_directories.append(cropped_folder)\n",
    "                      \n",
    "              cropped_file_name = person_face  + str(count)+ \".png\"\n",
    "              cropped_file_path = cropped_folder + \"/\" + cropped_file_name\n",
    "              cv2.imwrite(cropped_file_path,roi_color)\n",
    "              person_file_names_dictionery[person_face].append(cropped_file_path)\n",
    "              count+=1\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea5645dc-0376-4335-9360-e7c88d6f7ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dictionery = {}\n",
    "count = 0 \n",
    "for person_face in person_file_names_dictionery.keys():\n",
    "    class_dictionery[person_face] = count\n",
    "    count +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3f343e8-02ab-4646-aad9-3a90bfc4ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= [] #model input\n",
    "Y = []  #model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54815586-2e55-4bb8-b831-c8f5411ffd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/sqtjt7tj60zc4gdw10f4yq1c0000gp/T/ipykernel_13992/1510256237.py:20: RuntimeWarning: invalid value encountered in cast\n",
      "  imageArray_H= np.uint8(imageArray_H)\n"
     ]
    }
   ],
   "source": [
    "#Staking initial image and wavelet image\n",
    "for person_face, training_file in person_file_names_dictionery.items():\n",
    "    for training_image in training_file:\n",
    "        image = cv2.imread(training_image)\n",
    "        if image is not None:\n",
    "         saclled_raw_image = cv2.resize(image,(32,32))\n",
    "         image_har =wavelet2d(image,'db1',5)\n",
    "         sacalled_image_har = cv2.resize(image_har,(32,32))\n",
    "         combined_image = np.vstack((saclled_raw_image.reshape(32*32*3,1),sacalled_image_har.reshape(32*32,1)))\n",
    "         X.append(combined_image)\n",
    "         Y.append(class_dictionery[person_face])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c01c4bf1-8b75-40ac-8344-ff2979708cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping  to (40,4096), and converting to flaot\n",
    "X = np.array(X).reshape(len(X),4096).astype(float)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b1d4bca-23c9-459e-ba8f-c6d7e0c2d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameter Tuning (GridSearchCV)\n",
    "#Dictonery to hold model details for parameter tuning\n",
    "\n",
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params' : {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'randomforestclassifier__n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'logisticregression__C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23537d68-723d-4579-8122-5a83caaf9d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [] #Keep track of thE scores\n",
    "best_estimators ={} #Store the best estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46fcc3e2-ecd1-4685-9800-d0ea09d25d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo, mp in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    scores.append({\n",
    "        'model': algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "34da277a-3a57-4207-9aea-531aa0442948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68ba1b8f-a372-4716-a75e-f69133db6fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2727272727272727"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['svm'].score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58be9430-f8fc-4862-807e-3d3aa2b819e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36363636363636365"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['random_forest'].score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "215981ae-3bab-4c62-8c79-918ea21c0db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['logistic_regression'].score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc85ee97-be2f-4ffd-82f8-172b857488b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = best_estimators['logistic_regression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "490ff1a1-c2f9-4cf0-9b95-b51034cfdb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1],\n",
       "       [3, 5]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test, best_clf.predict(X_test))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d222839-4fb9-4369-a7f0-974d9168b810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
